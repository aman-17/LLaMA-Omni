{
  "stage": 1,
  "resume_from_checkpoint": null,
  "model_name_or_path": "allenai/OLMo-2-0425-1B-Instruct",
  "version": "olmo",
  "freeze_backbone": false,
  "tune_speech_projector": true,
  "tune_speech_encoder": false,
  "tune_speech_generator_only": false,
  "speech_encoder_type": "whisper",
  "speech_encoder": "tiny.en",
  "pretrain_speech_projector": null,
  "speech_projector_type": "linear",
  "speech_generator_type": "ctc",
  "ctc_decoder_config": "(2,4096,2,11008)",
  "ctc_upsample_factor": 25,
  "ctc_loss_weight": 1.0,
  "unit_vocab_size": 1000,
  "speech_encoder_ds_rate": 5,
  "speech_encoder_hidden_size": 384,
  "data_path": "/data/input/amanr/LLaMA-Omni/InstructS2S-200K/instruct_en_train.json",
  "validation_data_path": "/data/input/amanr/LLaMA-Omni/InstructS2S-200K/instruct_en_val.json",
  "is_multimodal": true,
  "input_type": "mel",
  "speech_normalize": false,
  "mel_size": 80,
  "has_tgt_units": false,
  "output_dir": "./outputs/stage1",
  "num_train_epochs": 3,
  "per_device_train_batch_size": 8,
  "per_device_eval_batch_size": 4,
  "gradient_accumulation_steps": 1,
  "eval_strategy": "steps",
  "eval_steps": 10000,
  "save_strategy": "epoch",
  "save_steps": 1,
  "save_total_limit": 3,
  "learning_rate": 2e-06,
  "weight_decay": 0.0,
  "warmup_ratio": 0.03,
  "lr_scheduler_type": "cosine",
  "logging_steps": 10,
  "remove_unused_columns": false,
  "dataloader_drop_last": false,
  "dataloader_num_workers": 4,
  "dataloader_pin_memory": true,
  "max_grad_norm": 0.3,
  "speech_projector_lr": null,
  "report_to": "wandb",
  "run_name": "olmo-omni-stage1"
}